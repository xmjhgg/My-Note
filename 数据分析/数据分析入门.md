
# 数据分析-决策树

## 基本概念

### 信息熵与纯度
- 纯度  
纯度是一种用来衡量数据信息的分歧度，分歧度越大则纯度越低，分歧度越小则纯度越高；  
举一个例子：
有三个数据集合：  
  - 集合 1：6 次都去打篮球；  
  - 集合 2：4 次去打篮球，2 次不去打篮球；  
  - 集合 3：3 次去打篮球，3 次不去打篮球；  
以上三个集合的纯度高低排行： 集合1>集合2>集合3，集合3的纯度最低

- 信息熵  
信息熵用来衡量数据的不确定度。数据的不确定度越大则信息熵越大，数据的不确定度越小则信息熵越小。  
举一个例子：  
  - 集合 1：5 次去打篮球，1 次不去打篮球；  
  - 集合 2：3 次去打篮球，3 次不去打篮球；
以上两个集合的信息熵大小排行：集合2>集合1，集合1的信息熵最小

- 信息熵与纯度的关系  
信息熵与纯度成反比， 信息熵越大则纯度越低，信息熵越小则纯度越高。  

以一个生活中的例子：如果一个人一天专心只做一个事情，那么信息熵小纯度高，效率好；如果一个人一天要做很多事情，那么信息熵大纯度低，效率往往也不会很高。  

## 决策树分类算法：ID3和C4.5
决策树学习通常包括三个步骤：
1. 特征选择。选取最优特征来划分特征空间，用信息增益或者信息增益比来选择
2. 决策树的生成。ID3、C4.5、CART
3. 剪枝  


## 总结优缺点：
### ID3:
优点：  
算法简单，通俗易懂
缺陷：  
1. 无法处理缺失值
2. 只能处理离散值，无法处理连续值
3. 用信息增益作为划分规则，存在偏向于选择取值较多的特征。因为特征取值越多，说明划分的 
越细，不确定性越低，信息增益则越高
4. 容易出现过拟合

### C4.5:
优点：  
1. 能够处理缺省值
2. 能对连续值做离散处理
3. 使用信息增益比，能够避免偏向于选择取值较多的特征。因为信息增益比=信息增益/属性 
熵，属性熵是根据属性的取值来计算的，一相除就会抵消掉
4. 在构造树的过程中，会剪枝，减少过拟合
缺点：  
构造决策树，需要对数据进行多次扫描和排序，效率低