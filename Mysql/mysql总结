## 1.一条查询语句的执行过程（Mysql的架构）

MySQL由下图组成：

<img src="https://static001.geekbang.org/resource/image/0d/d9/0d2070e8f84c4801adbfa03bda1f98d9.png" style="zoom: 25%;" />



接下来我们通过一条SQL语句一步步分析Mysql中各个组件的作用和Mysql的执行过程

```sql
select * from t where id = 1;
```



### 连接器

#### 连接器的作用

连接器负责和客户端建立链接、获取权限、维持、管理连接



#### 连接器的工作流程

```sql
mysql -h$ip -P$port -u$user -p
```

连接器是是我们使用MySQL的第一步，当我们要使用MySQL时，需要通过这条命令来和MySQL建立连接，在完成了TCP的三次握手后，MySQL的连接器就开始验证我们的账号密码

- 如果不正确就返回一个

`Access denied for user`的消息给客户端，然后断开此次连接

- 如果正确则去权限表中查询出用户所有的权限，之后这个连接执行的SQL语句都时基于此时查询出来的权限，也就是说即使权限表有更新，已经建立的连接不会受到影响



#### 连接占用内存多的处理方法

Mysql在执行过程中使用到的内存是存放在连接里，只有连接断开后才会回收，长连接累积起来可能会占用大量的内存。

有两种解决方法：

- 可以考虑定时断开一些长连接

- 在MySQL5.7之后的版本里可以通过执行`mysql_reset_connection`来重置连接资源，这个命令不需要重连和验证权限，只会把连接恢复到初始的状态



### 查询缓存

之后就到了查询缓存这一组件中（Mysql8.0之前，MySQL8.0之后移除了查询缓存）

查询缓存是以key-value的形式来进行缓存，key是要执行的SQL语句，Value就是查询结果，如果查询缓存中存在我们要执行的SQL那么就会直接返回结果给客户端

- 注意：一般不建议开启查询缓存，因为只要一张表上有任意的更新，都会导致这张表上的查询缓存失效，对于更新频繁的表来说，查询缓存的弊大于利，只有几乎是一张静态的表才比较适合使用查询缓存



### 分析器

如果查询缓存没有命中，那么就到了分析器这一步，分析器就是对我们执行的SQL语句进行解析，得知我们要做什么。

首先进行对SQL进行词法分析，识别出里面的字符串分别是什么、代表什么，比如从select 中得知这是一条查询语句，把字符t识别成表t，把“id”识别为“列ID”。

下一步就是进行语法分析，判断我们要执行的SQL语句是否满足MySQL的语法规则

分析器分析完成后，会对用户的权限进行验证



### 优化器

通过了分析器后，优化器会选择一个一个执行效率更高的方案来处理这条语句

比如：是采用索引来查询还是进行全表扫描



### 执行器

通过分析器知道了要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。

执行器首先会验证是否对相关的表有执行权限（为什么还要在这里验证权限，因为有的SQL会涉及到表的触发器、存储引擎等，存储引擎等对象在分析器是取不到的，因为分析器只是逻辑上的组件，只有到执行器这一阶段才和存储引擎打交道）。

有权限的话，

1. 执行器就会调用存储引擎提供的接口，获取这张表的第一条数据，判断是否满足条件，满足条件的话就加入结果集中，
2. 之后再调用接口获取下一行数据，再判断
3. 重复2过程，直到表的最后一行，然后将结果集返回



### 总结

这一章说明了MySQL的基础架构和架构中各个组件的执行过程



## 2.一条更新语句的执行过程（redo log 和bin log）

上一章介绍了一条查询语句的执行过程，这一章则来说一下更新语句的执行过程

```sql
update t set name = "张三";
```

更新语句一样会经过上面的连接器、分析器、优化器、执行器。

不同的是，因为MySQL中存在“事务”这一重要特性，因此还涉及到失败回滚等，所以更新还多了两个模块：

redo log和bin log。



### redo log

- flush

  当我们执行一条更新语句时，会将这条更新语句记录到redo log中，并更新在内存中的记录，此时还没有更新到磁盘中，然后就返回给客户端更新成功的信息，MySQL会在合适的时候，也就是MySQL认为系统压力比较小的时候将redolog 中记录的操作执行到磁盘中，这一过程称为 flush（当然即使压力大，MySQL也会见缝插针似的进行flush）

- redo log的存储结构

  redo log是以一个环形结构来存储语句，当这个环形的写入点快追上最早的存储点时，就会将最早存入到redolog里的语句flush到磁盘中，留下空间来放新的要写入的语句

  <img src="https://static001.geekbang.org/resource/image/16/a7/16a7950217b3f0f4ed02db5db59562a7.png" style="zoom: 50%;" />



### bin log

和redo log不同的是 binlog是属于 server层的引擎，也就是所有引擎都有的一个日志系统，开启bin log后，对MySQL进行修改的语句，都会记录到bin log中，因为binlog的存在，MySQL能为我们提供更多的功能，如主备、主从等

- bin log的存储结构

  bin log不是环形结构，是以追加写的形式来进行存储的，并不会删除原有的日志记录。每当我们存储满了一个binlog文件，就会在这基础上再新建一个binlog文件，再写入到这个文件中



### 日志的两阶段提交

- 为什么会有两个日志系统？

  redolog是innodb引擎独有的，一开始MySQL中并没有InnoDB，也不支持事务，Bin log并不能保证事务的正确性的（比如数据更新到完成了，但是在写入到日志系统时失败了，binlog中丢失了这条数据的记录，那么日志和数据就失去了正确性）。因此innodb自己实现了一套日志系统来支持系统异常时保证事务正确性的能力，这套系统就是redo log

- redo log如何保证事务的正确性

  这里就要提到日志的两阶段提交

  - 在事务执行期间出现了异常重启：这时候的事务没有提交，数据并没有写入到磁盘中，因此没有影响

  - 在事务执行完成，提交时出现了异常：

    - 这一部分就涉及到了事务的两阶段提交

      1. redo log首先会写入磁盘，这时候事务处于prepaer阶段
      2. 写入binlog
      3. binlog写入完成后，这时才认为事务成功执行

      异常重启后，MySQL会对比redolog和binlog中的内容

      此时会有三种情况：

      - redo log和bin log中没有和这个事务有关的记录，就是在1阶段中执行出现了异常，由于都没有记录，这条事务自然也没有提交到磁盘中，没有影响

      - redo log中有记录，binlog中没有相关记录，那么可以判断出是在2执行期间出现了异常，由于Binlog中没有日志，认定这条事务执行失败，MySQL不会将数据写入磁盘中
      - redo log中有记录，binlog中也有记录，那么就是在3阶段出现了异常，由于两个日志中都有相关的记录，可以认定这个事务时执行成功的，MySQL会将这个事务标记为成功，由redolog来找机会flush

### 总结

这一章介绍了MySQL对更新语句的执行流程、bin log、redo log



## 3.事务的隔离性

### 事务隔离性介绍

事务的执行往往是处于并发的状态，同一时间会执行多个事务，事务的隔离性就是控制并发事务间的相互影响范围

事务的隔离性有四个级别：

- read uncommit：读未提交，事务在执行期间可以读到其他事务还没有提交的修改
- read commit：读提交，事务在执行期间只能读取到其他事务已经提交的修改
- repeatable read：可重复度，事务在执行期间不会去读取其他事务的修改（即使其他事务已经提交了也不读取）

- serializable：串行化，事务在执行期间会对每个操作加锁，修改时对行加写锁，读取时加读锁，遇到冲突需要等其他事务先释放锁

### 事务隔离性实现原理

InnoDB表中的每一行记录其实有多个版本，每个事务对一行记录进行修改时，会给这个修改的记录打上自己的事务ID，事务ID会保持严格的递增。

事务的隔离的实现就是基于这个多版本的记录，每个事务在启动时，会创建一个一致性视图，这个一致性视图可以理解为一个由3个部分组成的数组。

- 第一个部分，也称为低水位：

  事务开启时，已经提交的事务ID

- 第二个部分，中水位：

  事务开启时，正在执行的事务ID

- 第三个部分，高水位

  事务开启时，还没有启动的事务

有了这个一致性视图

- 在可重复读隔离性级别下，事务在对记录进行操作时，就会判断记录行上最新的事务ID是否处于低水位
  - 如果处于低水位，那么这个事务就会去读取这个记录上数据。
  - 如果处于中水位，那么这个事务就会回滚这个记录，直到之前版本的记录行的事务ID小于当前事务的ID
  - 如果处于高水位，那么就说明这个记录的最新的修改是在当前事务开启之后启动的事务执行的，对于可重复而言，一样不能读取，一样进行中水位的处理
- 对于读提交而言，事务每执行一个SQL都会创建一致性视图，这样就保证每次已经提交的修改都处于低水位中



### 总结

这一章说明了事务的隔离性以及事务的一致性视图



## 4.为什么InnoDB选择B+树来作为索引结构

如果我们假设InnoDB不采用B+树作为索引，而使用其他的数据结构来作为索引的话会怎么样

### 如果使用Hash表来作索引

Hash是一种经常用于作索引快速访问的数据结构（即Java的Map）通常采用一个数组+链表或者数组+树的形式，来达到快速读取的效果。如果它来作为InnoDB的索引，可以做到索引快速访问的效果，但是Hash表只适合用来做等值查询（即 where id = 1这样的查询），如果是where id > 2 这样的查询，由于Hash表是随机存储，没办法进行这样的查询，就需要进行全表扫描了。

总结一下Hash表的优缺点：

- 等值查询快
- 不支持范围查询



### 如果使用有序数组作索引

采用有序数组作索引，对于等值查询，我们可以用二分法的查询方式来进行查找，效率也很快；

对于范围查询根据数组的有序性，也可以很快的进行读取；

但是我们要维护有序数组，对于修改的操作，就会涉及到数组内元素移动的问题，如果数组很长，每次修改都需要移动大量的数组

总结一下有序数组的优缺点：

- 支持等值、范围查询
- 对于修改的维护代价大



### 如果采用顺序二叉树作为索引

二叉的好处在于对于修改而言，不需要移动过多的数据，数据量比较小时，顺序二叉树也可以做到快速读取数据。但是，二叉树毕竟是基于链表，如果数据量多，就会导致树的层级过高，要定位数据时，就需要遍历多个节点。

总结一下二叉树的优缺点：

- 支持等值、范围查询
- 数量量大时，读取速度慢



### 采用B+树作为索引

到这里，大家就比较容易理解为什么InnnoDB采用B+最为索引的数据结构

B+树，是一颗固定3层的多叉树，每个叶子节点是一个有序数组，可以说是结合了有序数组的快速查询、范围查询的优势以及树的方便修改的优势，并且树只有3层，每次访问一个数据最多进行3次的IO操作（大多数情况下树的第一层第二层都在内存中，只需要一次IO），这一点更符合MySQL查找数据的特性。虽然可能在新增或者删除时发生页分裂的情况，但是如果保持索引的递增性，可以很好的降低页分裂的发生概率。

总结一下B+树的优缺点

- 支持等值、范围查询，修改的维护代价小，访问次数小

- 页分裂会造成一定的性能影响，保持索引的有序性可以降低这一影响

### 总结

这一章总结了Hash表、有序数组、顺序二叉树、B+树作为Innodb索引数据结构的优缺点



## 5.索引优化

### 回表

InnoDB 的索引组织结构



以这条SQL为例

```sql
select * from T where k between 3 and 5;
```



执行流程：

1. 在 k 索引树上找到 k=3 的记录，取得 ID = 300；
2. 由于查询数据在主键索引上，所以要再到 ID 索引树查到 ID=300 对应的 R3；
3. 在 k 索引树取下一个值 k=5，取得 ID=500；
4. 再回到 ID 索引树查到 ID=500 对应的 R4；
5. 在 k 索引树取下一个值 k=6，不满足条件，循环结束。



在这个过程里，从非主键索引树回到主键索引树查询就是**回表**，这上面的过程中，回表了两次（2和4）



#### 覆盖索引

如何每次查询非主键索引，都需要进行一次回表，那对性能的消耗还是不少的，有什么手段来减少回表的次数？

覆盖索引，就是用来减少回表次数的有效手段，以上面的查询语句为例，如果我们执行的SQL是这样的

```sql
select ID from T where k between 3 and 5
```

这时候只查ID，因为ID在字段k的索引树上已经有了，所以可以直接提供查询结果，不需要在回表。在这个查询里面k所引述已经“覆盖”了我们需要的查询结果，这就被称为覆盖索引。

**由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。**



基于覆盖索引，可以再思考一个问题：在一个市民信息表上，是否有必要将身份证号和名字建立联合索引？

如果说有一个频繁的请求是通过身份证来查询姓名的，那么这个联合索引是有必要的，通过覆盖索引，减少了回表次数，提高了请求的执行速度。

不过通过冗余索引来提高执行速度的代价就是空间的消耗，这是开发时需要进行的取舍了



### 最左前缀原则

B+树的数据节点是一个复合的数据结构，在构建节点是复合数据（如 name，age,sex）也就是，索引是联合索引，的时候会遵循最左前缀原则：根据节点创建的顺序来进行排序。

- 比如

  联合索引是（name,age,sex），那么就会以name为第一排序目标，name相同时以age进行排序，age相同则以sex进行排序。

- 匹配原则：

  比如当 (张三,20,F) 这样的数据来检索的时候，b+ 树会优先比较 name 来确定下一步的所搜方向，如果 name 相同再依次比较 age 和 sex，最后得到检索的数据；但当 (20,F) 这样的没有 name 的数据来的时候，b+ 树就不知道第一步该查哪个节点，因为建立搜索树的时候 name 就是第一个比较因子，必须要先根据 name 来搜索才能知道下一步去哪里查询，那么就不会走索引，进行全表嫂扫描。



#### 建立联合索引的第一原则

根据上面的最左前缀原则，如果我们要给某个字段建立索引，同时这个字段又要建立一个联合索引，那么如果能通过调整顺序来使这个字段匹配最左前缀原则少建立一个索引，那优先考虑这种顺序



### 索引下推

上面的最左前缀原则告诉了我们哪些字段匹配了索引最左部分，那么如果查询出来的索引的右边不匹配查询条件，那么MySQL会怎么处理呢？

- MySQL 5.6之前：只要查询条件的一个条件匹配索引的最左字段，那么就会回表查询整行数据，再判断是否符合查询条件

  比如：联合索引是（name,age,sex），索引A的值是（张三，19，男，主键ID:200），我们的查询条件是name=张三 and age = 20，那么mysql在查询到索引A时，匹配到name是张三，就会拿着索引的主键ID回表查询数据，之后再查到age=19才认为不符合条件，舍弃这条数据

- MySQL5.6之后引入了**索引下推**，MySQL在查询会接着匹配索引中含有查询条件的字段，不匹配的话就不会回表去查。

  比如：还是用上面的例子，匹配到name是张三后，会继续匹配索引的age，发现是19，就舍弃这条数据

### 总结

这一章介绍了MySQL索引中的回表、最左前缀、索引下推、联合索引的匹配过程



## 6.普通索引和唯一索引脏页以及change buffer

### 唯一索引

唯一索引顾名思义，索引的值在表中是唯一的



### 普通索引

普通索引则是一个普通的索引，索引的值可以重复



### 两者的查询过程

- 查询过程的区别

  假设有两条查询，where的条件分别是唯一索引的字段和普通索引的字段。

  1. 查询开始都是从索引B+树的树根开始查询

  2. 按层查询到叶子节点，
  3. 在叶子节点处用二分法来定位记录

  对于前三步两者的查询过程都是一致的。但是在定位到第一条数据后，唯一索引因为其唯一性会在查询到后会立刻返回，而普通索引则会继续扫描下一行，如果下一行不匹配的话才返回。

- 查询性能的区别

  两者在查询性能方面的区别微乎其微，因为引擎在读取索引树的叶子节点时会将整个数据页读取到内存中，再进行定位，所以要多做一次的查询动作无需从磁盘中读取，只需要进行一次指针寻找和计算，这点消耗可以忽略不计。当然，如果要定位的数据正好是数据页的最后一个，那么还是需要从磁盘中载入内存，这个消耗会稍微多一点，但是一个数据页可以放近千个key，这个概率很低，也可以忽略不记。



### 两者的更新过程

上面说明了两者查询的过程中的差别，但其实这两者最大的区别在于更新。



#### change buffer

在说更新过程之前，需要先介绍一下change buffer

change buffer可以理解为InnoDB在内存中的一个空间，当我们执行一条更新操作时，如果要更新的数据没有在内存中，**在不影响数据一致性的前提下(也就是没有要当前读这条数据的需求)**，InnoDB会将这些更新操作缓存在change buffer中，并记录到redolog中（这一步很关键，防止由于异常更新操作丢失），然后就返回这个更新操作成功。

- change buffer的merge

  change buffer的merger就是将change buffer中缓存的更新执行，把更新持久化到磁盘中。

  当有读取请求要读取change buffer中缓存的更新操作对应的记录时，change buffer就会把缓存中的更新操作先执行。

  除了上面的操作会触发merge，innodb后台会有线程定期的merge，还有当数据库正常关闭的时候也会触发merge。

- 为什么要这么做

  因为每次进行merge时会将数据页载入到内存中，此时change buffer中缓存的多个更新记录可能都在同一个数据页中，一次性的更新掉，减少了将磁盘载入内存的次数。

#### 更新过程

知道了change buffer后，再来看一下更新过程：

分两种情况：

- 要更新的记录所在的数据页在内存中：

  - 唯一索引：

    找到要更新的位置，判断更新后会不会和其他索引值重复，不重复的话就进行插入或者更新

  - 普通索引：

    找到要更新的位置，更新

  这一步看，如果数据在内存中，那两者的性能差别就只是唯一索引会增加一个判断，性能消耗很小

- 要更新的记录所在数据页不在内存中

  这种情况下，就涉及到了上面说的change buffer

  - 唯一索引

    由于唯一索引更新时，都需要判断和其他索引是不是会引起冲突，所以都必须要当前读数据的最新值，因此使用了唯一索引的更新操作不会使用changebuffer，每次都会将数据页从磁盘加载到内存中，再进行查找、更新

  - 普通索引

    普通索引因为不需要判断索引冲突的问题，所以普通索引在更新时，只是将更新操作记录到change buffer中，就返回。

  这一步看，普通索引因为change buffer的存在，无需读取磁盘到内存中，所以对于更新操作的响应速度会比唯一索引快

### 索引的选择

知道了唯一索引和普通索引在查询和更新过程的区别，两者查询性能消耗差距微乎其微。而更新中普通索引的性能更好，所以应当尽量选择普通索引。

当然，普通索引并非绝对，如果对于表中的数据来说，经常要更新完成后需要立即读取，那么普通索引相当于要额外维护一个change buffer，这时候不如直接使用唯一索引。



### 总结

这一章介绍了唯一索引和普通索引在查询于更新上的区别以及change buffer。

## 7.Mysql查询时索引选择规则



Mysql索引的选择是由优化器决定的，

优化器的索引选择受到以下几个因素共同影响：



### 查询时扫描行数

扫描行数是影响执行代价的因素之一，扫描行数越少，意味着磁盘访问的次数少，CPU的消耗就少

- 优化器是如何判断要扫描多少行呢？

  查询语句在真正执行之前，并不能精确的知道满足查询条件的行数有多少，所以在选择索引时，会选择区分度更好的索引，也就使用这个索引可以更快的找到匹配查询条件的记录。

  - 索引的区分度是如何计算的

    一个索引树上不同的值越多，那么这个索引的区分度就越大。一个索引数上不同的值的个数，在mysql中称为“基数”（cardinality），可以通过下面这条命令查看索引的基数

    ```sql
    show index from t;
    ```

    这个基数的计算方法并不是将表中的每行数据都取出来一行行的如果不同基数就加一，这样的代码太高，而是采用了一种采样统计的方法：

    - 采样统计：

      InnoDB会选择N（这个N可以配置）个索引上的数据页，统计这些数据页上的不同值，然后取得一个平均值，再乘以这个索引的数据页数，最后的结果就是索引的基数。

      因为表的数据是会更新，当变更的数据行数超过的表的总行数1/M(这个M可以配置)，就会触发触发一次采样统计

      这个采样统计有时候基数容易不准，除了自动触发，也可以通过下面的命令手动触发采样统计

      ```sql
      analyze table t;
      ```

- 扫描行数还要加上回表的次数、是否排序等

  如果我们使用的是普通索引，而普通索引并没有覆盖查询结果，那么还需要加上回表的次数，这也是有时候会导致mysql不走索引而选择全表扫描的原因。

  如果查询条件中，根据某个索引来排序，那么根据这个索引来查询出来的数据就不需要再进行排序了，扫描行数就会变少，这也会影响到优化器对扫描行数的判断

### 索引选择异常的解决方法

如果我们碰到了明明有更好的索引选择，而优化器却不选择的情况，有以下几种方法

- 手动触发重新统计索引的信息

  ```sql
  analyze table t;
  ```

- sql语句中强制指定选择索引

  ```sql
  select * from t force index(a) where a between 10000 and 20000;
  ```

- 引导优化器的索引选择

  比如在sql语句后根据索引进行排序



### 总结

这一章说明了优化器的索引选择逻辑、索引的区分度、索引选择异常的解决方法



## 8.如何给字符串字段加索引合适

这一章的内容介绍一下如何节省索引占的空间，内容比较简单

### 前缀索引

那么要如何节省索引的空间呢？创建索引的时候可以选择截取索引字段的某一部分来作为索引，淡然也可以不截取，对应的SQL如下

```sql
mysql> alter table SUser add index index1(email);

mysql> alter table SUser add index index2(email(6));
```

第一种SQL就是包含了字段的整个字符串，而第二种索引截取了字段的前6个字节，对应所占的空间也就更小，这种截取的索引就是前缀索引



### 前缀索引和普通索引的查询区别

一上面的索引树为例，如果我们要执行下面这条SQL

```sql
select id,name,email from SUser where email='zhangssxyz@xxx.com';
```

- 普通索引
  1. 从索引树上查出值为"zhangssxyz@xxx.com"的记录，取得这个索引对应的主键
  2. 到主键索引树上再判断email的值是否正确，将这条记录加入结果集
  3. 回到索引树上继续查找下一条，如果下一条不是"zhangssxyz@xxx.com"，那么就返回查询结果集
- 前缀索引
  1. 从索引树上找到值为“zhangs”的记录，取得主键
  2. 到主键索引树上判断email的值是否正确，如果正确则加入结果集
  3. 回到索引树上继续查找下一条，如果下一条索引值不是"zhangs"，那么就返回查询结果集

从这两者的查询来看，前缀索引可能会因为索引值比较相似，而增加查询的次数

所以，如果需要是哦那个前缀索引来节省空间，又不太消耗多的性能，需要对索引选择一个合适的长度。

- 前缀索引对覆盖索引的影响

  覆盖索引是如果索引树上可以获取到本次查询需要的值，那么就不再回表，因为前缀索引只包含了记录的一部分，所以一定是需要回表查询的。

  因此**前缀索引无法使用覆盖索引来优化查询速度**，这也是使用前缀索引需要考虑的



### 总结

这一章介绍了前缀索引，前缀索引和普通索引的区别以及前缀索引的取舍

## 9.什么情况下SQL语句中的索引字段会失效

有时候SQL中对索引字段的不当操作会导致SQL的索引失效，进行全表扫描，这一章说明比较容易发生索引失效的场景



### 对条件中的索引字段使用函数

比如我们要查询在7月份注册的用户，可能会这么写：

```sql
select count(*) from tradelog where month(t_modified)=7;
```

对索引字段使用函数，就会让索引失效，原因在于

索引能够快速定位是因为B+树的有序性，对于MYSQL而言，使用了函数后，就当于让mysql在一颗日期的索引树上找一个7的数字，在B+树的第一层就不知道要怎么查找了，破坏了索引的有序性，因此优化器就会放弃使用索引，而走全表扫描。

- 对索引字段进行简单的加减也会让索引失效

  ```sql
   select * from tradelog where id + 1 = 10000
  ```

  虽然上面这条SQL并没有破坏索引的有序性，但是优化器还是不能明确的用哪个id去找要的记录，索引仍会失效。

  如果将sql改写成下面这条就可以用到索引，这样优化器就可以明确知道用ID去找哪条记录

  ```sql
   select * from tradelog where id  = 10000 - 1;
  ```



### 隐式类型转换

有时候主键ID的类型是varchar，但是我们在SQL语句中却这么写

```sql
select * from tradelog where id=110717;
```

这样的SQL可以执行，但是会进行一个类型转换，实际执行的SQL语句就变成了下面这条，也就发生了刚刚上面说的情况，对索引字段使用函数

```sql
select * from tradelog where  CAST(tradid AS signed int) = 110717;
```

- 类型转换规则

  如果字符串和数字做比较的话，是将字符串转换成数字



### 隐式字符编码转换

有时候两张关联表做字段查询时，两个表的编码格式不同，也会让索引失效，失效原因和对索引字段使用函数一样。

发生隐式字符串编码转换时的SQL相当于：

```sql
select * from trade_detail  where CONVERT(traideid USING utf8mb4)=$L2.tradeid.value; 
```



### 总结

这章总结了三种会让索引失效的情况，其实都都是同一回事：对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走索引



## 10.InnoDB flush脏页

有的时候明明是同样的SQL，执行时间却差距比较大，而且这种情况只是偶尔发生，很难复现，这一章将介MySQL为什么会发生这种现象。



### 脏页与干净页

前面在介绍更新语句的执行时，InnoDB有一个redo log的日志系统，这个日志记录了更新操作的记录，是InnoDB用来解决系统故障，Mysql重启后需要进行数据回滚的必要系统之一。

#### flush

Innodb对于更新操作，就是将这条更新操作记录在redo log中并更新内存中现有的数据页，然后就返回给客户端更新成功，当然innodb会找时间把redolog中记录的更新操作持久化到磁盘中，就是把内存中的数据写入到磁盘中，这个行为称为 flush



#### 脏页和干净页

- 脏页

  脏页就是磁盘中的数据和内存中的数据不一致，需要flush的数据页

- 干净页

  干净页则是flush后， 磁盘中的数据和内存中的数据一致的数据页



### 什么时候会flush

- redolog满了，无法再记录新的更新操作，这时候所有的更新操作都会停止，需要先让redolog空出一部分，也就是flush一些脏页，有新的可写入空间了才能继续进行更新操作。
- 内存不足，而InnoDB又需要从磁盘中读入新的数据页，这时候需要淘汰现有数据页，如果这个数据页是脏页，那就会将这个脏页flush
- Innodb认为当前系统压力比较小，可以进行flush，那么InnoDB就会自主的进行flush。当然，压力比较大的时候redolog更容易满，所以InnoDB也会见缝插针似地找时间flush
- MySQL正常关闭的时候，MySQL会把内存中的所有脏页都flush



### 性能偶尔变差的原因

知道了flush的时机，我们就能发现为什么偶尔MySQL的响应速度变慢，其实这时候大概就是MySQL正在flush。

对于上面4种情况，后两种其实都由MySQL自己主动flush，对于响应时间的影响不大，主要是前两种导致MySQL被动的flush。

- 一个查询语句要淘汰脏页个数太多，会导致响应时间变长
- redo log写满，更新语句全部堵住



### 对应的解决方案

InnodoDB的flush策略参考的就是上面性能变差的两个因素：

- 内存中脏页太多

- redolog写满

  

#### innodb_io_capacity

首先我们要告诉InnoDB所在主机的IO能力，这样innodb才知道要用怎样的速度去刷脏页，这个参数就是

innodb_io_capacity，这个值建议设置为磁盘的IOPS，磁盘的IOPS可以通过fio工具来测试。



#### innodb_max_dirty_pages_pct 

如果我们将innodb_io_capacity设置为磁盘的IOPS，总不能平时没什么压力也用全力去刷脏页，毕竟磁盘还需要为其他的业务服务，因此，这里还有一个参数innodb_max_dirty_pages_pct ，内存中脏页的比例上限，默认是75%

#### Innodb的刷脏页速度计算逻辑

假设当前内存的脏页比例为M，算出一个范围在0~100的数字，这个计算的伪代码如下

```sql
F1(M)
{
  if M>=innodb_max_dirty_pages_pct then
      return 100;
  return 100*M/innodb_max_dirty_pages_pct;
}
```

我们将这个计算后的结果记为X，影响X的主要因素就内存中脏页所占的比例

还有另一个计算逻辑，这个计算逻辑对应的结果记为Y，Y的范围也在0~100，计算逻辑是当前redolog可写入的序号和已经有记录的序号的位置之间的差值，这个差值越大，Y越大（就是redolog记载的记录越多，Y越大）。

innodb会取X和Y之间的较大值，我们将这个较大值记为R，之后indodb就会以innodb_io_capacity 乘以 R%的速度取刷脏页



因此我们想要解决mysql偶尔突然性能变差的方法就是合理的设置innodb_io_capacity，并且平时要多关注脏页比例，不要让它经常接近 75%。

脏页的比如可以通过下面的SQL获取

```sql
select VARIABLE_VALUE into @a from performance_schema.global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_dirty'; select VARIABLE_VALUE into @b from performance_schema.global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_total'; select @a/@b;
```



### 总结

这一章介绍了innodb的flush、flush的时机、决定flush速度的策略、MySQL会偶尔响应变慢的原因和解决方法

## 11.InnoDB表收缩空间的办法

这一章毕竟简单，首先提出一个问题，为什么把一个表里的一半记录都删除掉，表的文件却没有变小呢？



这个问题就涉及到了这次主题，InonoDB表的删除操作



### 数据行的删除流程

innodb的表都是以B+树的形式存储的，执行一条删除语句时，innodb并不会真正的删除这行记录，只会将这个记录所在位置标记为可复用，如果正好有插入数据要插入到这个位置，那么就会使用这个空间。

这也就是为什么明明删除了记录，表文件却没有变小的原因，如果删除了一半的记录行，只会让这棵树有许多空洞，真正的空间并没有释放。



### 收缩表空间：重建表

如果我们要消除表里的空洞，那么我们就需要重建表，新建一个比与表A结构相同的表B，然后把数据一行行的从表A里读出来再插入到表B中，因为B是一张新建的表，不会存在有空洞的情况，最后我们用表B替换表A，这样就起到了收缩表A的作用

表的重建过程可以直接用下面这条命令来重建

```sql
 alter table A engine=InnoDB 
```

这条命令的执行流程和前面的差不多，会自动完成转存数据、交换表名、删除旧表的操作。



### 总结

这一章介绍innodb中表的删除操作和收缩表空间的办法



## 12.count(*)、count(1)、count(主键)、count(字段)

在平时的开发中，我们经常会需要统计某一张表的行数，这时候就会用到count这个函数，这一章就介绍一下count函数的执行过程。



### count（*）的实现方式

count(*)在不同的MySQL引擎中有不同的实现方式

- MyISAM 把一个表的总行数存在了磁盘上，MyISAM的count(*)会直接返回这个数，执行速度非常快

- InnoDB则是老老实实的把表中的数据一行行的读出来，然后累加，当表的记录越来越多 count（）会越来越慢

  - 为什么InnoDB不像MyISAM这样把行数存储起来？

    这主要是因为InnoDB的多版本并发控制的原因，在多个事务执行中，每行记录都要判断这个记录是否对当前事务可见，MyISAM的做法并不适用于InnnoDB。

  - 补充说明：show table status中有一个TABLE_ROWS，这个数值是用于通过采样统计得到的表行数，与真正的表行数有误差，官方文档说误差可能有40%~50%，因此这个命令中的table_rwos并不能直接使用（最终原因还是因为innodb的多版本并发控制，这个只是次要因素）



### 四种count 哪个更快？



- count(主键)：

  InnoDB会遍历整张表，把每一行的id都取出来，返回给server层，server层判断是不可能为空，就逐行累加

- count(1)：

  InnoDB也会遍历整张表，但不取值，server层则对于每一行放以个数字1进去，server层判断不可能为空，就逐行累加

单比较这两个的话，count(1)会比count(主键)快，因为多了一步InnoDB取值和拷贝字段的操作

- count(字段)：

  count（字段）需要分两种情况：

  - 字段定义是not null:

    那么会一行行地从记录中读取这个字段，server层判断是不可为空，就逐行累加

  - 字段定义是允许null：

    那么server层还需要对每个值再多判断是否是null，不是null才累加

- count(*)：

  MySQL专门优化了 count(*) ， 引擎会遍历整张表但是不取值，server层逐行累加



经过上面的分析，可以得到结论：

count(*) > count(1) > count(主键) > count(字段)，如果没有特殊需求最好还是使用count( * )



### 总结

这一章介绍了count函数的执行过程，经常用的4种count性能分析



## 13.orderBy的执行过程

这一章来说明 OrderBy在MySQL内部是如何执行的



假设我们现在要从一个城市人员详情表里面获取城市名、人名、年龄，并根据人名排序，有对城市名建立索引

```sql
select city,name,age from t where city='杭州' order by name limit 1000 ;
```



### sort_buffer

在开始之前先介绍一下 sort_buffer ，这是MySQL专门为排序而开辟的一块内存空间，排序相关的操作在这块内存中进行



### 全字段排序

这条语句的执行过程就是这样：

1. 初始化sort_buffer，确定会在sort_buffer中放入name、city、age三个字段

2. 从city索引树中读取city = ‘杭州’的主键ID

3. 回表查询出city,name,age三个字段的值，存入sort_buffer中

4. 重复2、3，直到有记录不符合查询条件
5. 在sort_buffer中对空间内的数据按照name做快速排序
6. 取排序结果的前1000行给客户端

这种排序，称为全字段排序，就是需要的字段全都放入sort_buffer中排序



### rowid排序

上面的全字段排序，因为需要把查询需要的字段都放到sort_buffer中，这会导致sort_buffer里的每行数据太大，sort_buffer里能放入的数据行变少，如果MySQL认为一行的数据太长，那久会采用rowid排序

- sort_buffer最大行的大小可以通过参数： max_length_for_sort_data来设置，超过这个值就会采用rowid排序

所谓的rowid排序就是只把需要排序的字段和记录的主键放到sort_buffer中，sort_buffer中每行的数据就变少了，能放入的行数就变多。

使用了rowid排序，上面的sql执行流程就是这样：

1. 初始化sort_buffer，确定会在sort_buffer中放入name、id两个字段
2. 从city索引树中读取city = ‘杭州’的主键ID
3. 从主键 id 索引树取出整行，取 name、id 这两个字段，存入 sort_buffer 中；
4. 在sort_buffer中根据name排序
5. 取排序后的前1000行，并根据id的值回到原表中取出 city、name 和 age 三个字段返回给客户端。



### 外部排序

不一定每次的排序都可以在内存中直接完成，有时候2、3两步取出来的数据太多，sort_buffer中放不下，就会使用外部排序：Mysql将需要排序的数据分成12份，每一份单独排序后存在磁盘中的临时文件中，然后再把这12个有序文件合并成有序一个大文件。



- 如何判断排序语句是否使用了临时文件，也就是外部排序

  ```sql
  /* 打开optimizer_trace，只对本线程有效 */
  SET optimizer_trace='enabled=on'; 
  
  /* @a保存Innodb_rows_read的初始值 */
  select VARIABLE_VALUE into @a from  performance_schema.session_status where variable_name = 'Innodb_rows_read';
  
  /* 执行语句 */
  select city, name,age from t where city='杭州' order by name limit 1000; 
  
  /* 查看 OPTIMIZER_TRACE 输出 */
  SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`;
  
  /* @b保存Innodb_rows_read的当前值 */
  select VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = 'Innodb_rows_read';
  
  /* 计算Innodb_rows_read差值 */
  select @b-@a;
  ```

  在第二个结果集中的字段 number_of_tmp_files 就是表示这次排序使用到了多少个临时文件，如果这个值是0，就说明sort_buffer空间大于需要排序的数据类，排序在内存中就可以完成；反之就是使用了外部排序。



### 全字段排序 和 rowid排序比较

和全字段排序相比，rowid排序所需要的内存空间更小，代价是要回表多读取一次信息，因此上面那条SQL使用rowid排序会比上面的全字段排序多读取一千行

正常MySQL会优先考虑全字段排序，避免多读取一次磁盘的情况。如果MySQL认为内存实在太小，那么才会采取rowid排序。



### 不需要排序的orderBy

还是上面那条SQL，如果我们有一个联合索引是（city，name）

因为B+树的有序性，从(city,name)索引树上读取到city = '杭州'的记录时，name就已经是排好序了，不需要在到sort_buffer中进行排序，因此这条SQL的执行过程就变成了：

1. 从索引 (city,name) 找到第一个满足 city='杭州’条件的主键 id；
2. 到主键 id 索引取出整行，取 name、city、age 三个字段的值，作为结果集的一部分直接返回；
3. 从索引 (city,name) 取下一个记录主键 id；
4. 重复步骤 2、3，直到查到第 1000 条记录，或者是不满足 city='杭州’条件时循环结束。

这个查询过程既不需要临时表也不需要排序，通过explain来分析这条SQL，Extra 字段中没有 Using filesort 了，也就是不需要排序了，SQL的性能得到提高。

#### 覆盖索引

对上面这条SQL，还可以再进一步优化，就是使用覆盖索引，将上面的第二步回到主键索引取整行的操作省略

我们建立一个（city、name 、age ）的联合索引，在这个索引树上就可以取到我们需要的所有字段，因此上面的执行过程就变成了：

1. 从索引 (city,name,age)  找到第一个满足 city='杭州’条件的记录，取出其中的 city、name 和 age 这三个字段的值，作为结果集的一部分直接返回；
2. 从索引  (city,name,age) 取下一个记录，同样取出这三个字段的值，作为结果集的一部分直接返回；
3. 重复执行步骤 2，直到查到第 1000  条记录，或者是不满足 city='杭州’条件时循环结束。



### 总结

这一章介绍了OrderBy的两种执行流程，以及OrderBy的优化方法



